{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorly library\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TENSOR TO TENSOR REGRESSION v1    \n",
    "  Inputs:\n",
    "    X - Input Tensor, shape (N, I_1, ..., I_{M1})\n",
    "    Y - Output Tensor, shape (N, J_1, ..., J_{M2})\n",
    "    rank - The rank of the solution weights matrix\n",
    "    lambda_reg - how much l2 regularization to use\n",
    "    return_factors - whether to include the weight matrix factors along with the weight matrix itself\n",
    "    eps - the precision of our estimate\n",
    "    \n",
    "  Outputs:\n",
    "    W - weight matrix tensor, shape (I_1, ..., I_{M1}, J_1, ..., J_{M2})\n",
    "    factors - List of CP factors which forms the CP decomposition of W. Will only be returned if return_factors==True\n",
    "\"\"\"\n",
    "def tensor_to_tensor_regression_1(X, Y, rank, lambda_reg=1e-1, return_factors=False, eps=1e-6):\n",
    "    # Check that the N is consistent between X and Y tensors\n",
    "    if X.shape[0] != Y.shape[0]:\n",
    "        print(\"Wrong leading dimensions for tensors X and Y\")\n",
    "    \n",
    "    # Number of examples (leading dimension in the tensor)\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Setup the sizes of the X and Y matrices\n",
    "    I = reduce(lambda x, y: x * y, X.shape[1:])\n",
    "    J = reduce(lambda x, y: x * y, Y.shape[1:])\n",
    "    \n",
    "    # Initialize the u_r and v_r vectors which we will directly optimize\n",
    "    u_rs = [np.random.random(I)-0.5 for r in range(rank)]\n",
    "    v_rs = [np.random.random(J)-0.5 for r in range(rank)]\n",
    "    \n",
    "    # Matricize X and Y\n",
    "    X_mat = tl.unfold(X, mode=0)\n",
    "    Y_mat = tl.unfold(Y, mode=0)\n",
    "    \n",
    "    # Precompute some repeatedly used matrices\n",
    "    XtXpL = (tl.transpose(X_mat) @ X_mat) + lambda_reg * tl.eye(I)\n",
    "    XtXpL_inv = np.linalg.inv(XtXpL)\n",
    "    XtY = tl.transpose(X_mat) @ Y_mat\n",
    "    YtX = tl.transpose(XtY)\n",
    "    \n",
    "    steps = 0\n",
    "    prev_error = -1\n",
    "    #errors = [] # TODO: Remove for production (only used for testing)\n",
    "    # Keep optimizing until the error has converged\n",
    "    while True:\n",
    "        # For every rank of the weights matrix\n",
    "        for r in range(rank):\n",
    "            \n",
    "            # Update all the u_rs first\n",
    "            u_comp = tl.zeros(I)\n",
    "            # Do some ugly linear algebra\n",
    "            for r1 in range(rank):\n",
    "                # Only want cases where r1 != r\n",
    "                if r1 == r:\n",
    "                    continue\n",
    "                # Computing the summation in equations (13)\n",
    "                u_comp += (v_rs[r1] @ v_rs[r]) * (XtXpL @ u_rs[r1])\n",
    "            # More ugly linear algebra, finishing off the calculation from (13) \n",
    "            u_rs[r] = (XtXpL_inv @ ((XtY @ v_rs[r])-(u_comp / 2))) / (v_rs[r] @ v_rs[r])\n",
    "            \n",
    "            # Now update all the v_rs\n",
    "            v_comp = np.zeros(J)\n",
    "            # Do some ugly linear algebra\n",
    "            for r1 in range(rank):\n",
    "                # Only want cases where r1 != r\n",
    "                if r1 == r:\n",
    "                    continue\n",
    "                v_comp += (u_rs[r] @ XtXpL @ u_rs[r1]) * v_rs[r1]\n",
    "            v_rs[r] = ((YtX @ u_rs[r]) - (v_comp / 2)) / (u_rs[r] @ XtXpL @ u_rs[r])\n",
    "        \n",
    "        # Here comes the normalization step (ensures numerical stability)  \n",
    "        for r in range(rank):\n",
    "            u_scale = (tl.norm(v_rs[r], 2) / tl.norm(u_rs[r], 2)) ** 0.5\n",
    "            v_scale = 1 / u_scale\n",
    "            u_rs[r] *= u_scale\n",
    "            v_rs[r] *= v_scale\n",
    "        \n",
    "        # Compute the new error, this time ignoring regularization\n",
    "        W_mat = np.zeros((I, J))\n",
    "        for r in range(rank):\n",
    "            # Add each W_r\n",
    "            W_mat += tl.kron(u_rs[r], v_rs[r]).reshape(I, J)\n",
    "        # Use MSE to normalize the by the size of the tensor\n",
    "        error = np.square(Y_mat - X_mat @ W_mat).mean() + lambda_reg * np.square(W_mat).mean()\n",
    "        #errors.append(error)\n",
    "        # Determine if we have converged\n",
    "        if prev_error >= 0 and abs(prev_error - error) < eps:\n",
    "            print(\"Converged after\", steps, \"steps. Final Error:\", error)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Step:\", steps, \"Error:\", error)\n",
    "        # Reset the previous error\n",
    "        prev_error = error\n",
    "        # Next step\n",
    "        steps += 1\n",
    "        \n",
    "    \n",
    "    # TODO: Add functionality to make the factors\n",
    "    \n",
    "    return tl.reshape(W_mat, (X.shape[1:]) + (Y.shape[1:])) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 5.061624698862072\n",
      "Step: 1 Error: 5.335491109894079\n",
      "Step: 2 Error: 4.4700380983810755\n",
      "Step: 3 Error: 3.9390258590155547\n",
      "Step: 4 Error: 3.684024941495695\n",
      "Step: 5 Error: 3.6061418243456775\n",
      "Step: 6 Error: 3.6112425132332824\n",
      "Step: 7 Error: 3.640379583089283\n",
      "Step: 8 Error: 3.6663803940855915\n",
      "Step: 9 Error: 3.681947287045\n",
      "Step: 10 Error: 3.68873035634585\n",
      "Step: 11 Error: 3.6905187456440935\n",
      "Step: 12 Error: 3.690308366191057\n",
      "Step: 13 Error: 3.6897143634262375\n",
      "Step: 14 Error: 3.6893277998142864\n",
      "Step: 15 Error: 3.6892168193960995\n",
      "Step: 16 Error: 3.689275923513273\n",
      "Step: 17 Error: 3.6893947510374248\n",
      "Step: 18 Error: 3.6895082610743466\n",
      "Step: 19 Error: 3.689592757309681\n",
      "Step: 20 Error: 3.6896478116962337\n",
      "Step: 21 Error: 3.6896813270527478\n",
      "Step: 22 Error: 3.689701524404915\n",
      "Step: 23 Error: 3.689714209027369\n",
      "Step: 24 Error: 3.689722728484145\n",
      "Step: 25 Error: 3.689728784867512\n",
      "Step: 26 Error: 3.689733212747787\n",
      "Step: 27 Error: 3.689736467066588\n",
      "Step: 28 Error: 3.6897388542700518\n",
      "Step: 29 Error: 3.6897406132280275\n",
      "Step: 30 Error: 3.689741932905717\n",
      "Step: 31 Error: 3.6897429543378655\n",
      "Converged after 32 steps. Final Error: 3.6897437746239383\n",
      "(5, 7, 2, 3)\n",
      "3.593465446035915\n"
     ]
    }
   ],
   "source": [
    "N = 11\n",
    "X = np.random.random((N, 5, 7))\n",
    "Y = np.zeros((N, 2, 3))\n",
    "# Setup Y tensor with some dummy data\n",
    "for n in range(N):\n",
    "    x = X[n]\n",
    "    Y[n] = np.array([[x[0, 0] + x[1, 1] , 2 * x[1, 0] - x[3, 2], (x[4, 5] + 1) ** 2],\n",
    "                    [-x[1, 6] + 3 * x[1, 5] ,  - x[0, 6] - x[3, 3], (x[2, 5] + 2) ** 2]])\n",
    "# Now fit it\n",
    "W = tensor_to_tensor_regression_1(X, Y, 5, lambda_reg=1)\n",
    "print(W.shape)\n",
    "# We can verify our answer is correct with the following\n",
    "Y_pred = tl.tenalg.contract(X, range(1, tl.ndim(X)), W, range(tl.ndim(X) - 1))\n",
    "print(np.square(Y_pred - Y).mean()) # Should print the same as the final error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 4.0214449899317515\n",
      "Step: 1 Error: 4.615278855711329\n",
      "Step: 2 Error: 4.330122752733615\n",
      "Step: 3 Error: 3.9053734534798177\n",
      "Step: 4 Error: 3.6026137719382403\n",
      "Step: 5 Error: 3.4503076963740353\n",
      "Step: 6 Error: 3.399219947618061\n",
      "Step: 7 Error: 3.397285823498813\n",
      "Step: 8 Error: 3.410641701689073\n",
      "Step: 9 Error: 3.423343543054102\n",
      "Step: 10 Error: 3.4308872772046177\n",
      "Step: 11 Error: 3.4339501762629157\n",
      "Step: 12 Error: 3.434492264382796\n",
      "Step: 13 Error: 3.434083972665766\n",
      "Step: 14 Error: 3.433562029351891\n",
      "Step: 15 Error: 3.433216856867045\n",
      "Step: 16 Error: 3.4330632900403915\n",
      "Step: 17 Error: 3.4330291269262503\n",
      "Step: 18 Error: 3.4330451177581387\n",
      "Step: 19 Error: 3.433070386632795\n",
      "Step: 20 Error: 3.4330887479150083\n",
      "Step: 21 Error: 3.433097858556881\n",
      "Step: 22 Error: 3.433100518950238\n",
      "Converged after 23 steps. Final Error: 3.4331000359015005\n",
      "0.09400153160095215\n"
     ]
    }
   ],
   "source": [
    "# For timing\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "W = tensor_to_tensor_regression_1(X, Y, 5, lambda_reg=10)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexg\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:219: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Scale(64),\n",
    "    # transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_X = torchvision.datasets.CelebA(\"\", split='train', transform = transform, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_X,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "mnist_X_train = torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform2)\n",
    "mnist_X_test = torchvision.datasets.MNIST('../data', train=False,\n",
    "                       transform=transform2)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_X_train, batch_size=10000)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_X_test, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 1)\n"
     ]
    }
   ],
   "source": [
    "image_lst = []\n",
    "label_lst = []\n",
    "for (image, labels) in train_loader:\n",
    "    np_image = image.detach().numpy().reshape((10000, 28, 28))\n",
    "    labels = labels.detach().numpy().reshape((10000, 1))\n",
    "    image_lst.append(np_image)\n",
    "    label_lst.append(labels)\n",
    "X_train_mnist = np.concatenate(image_lst, axis=0)\n",
    "Y_train_mnist = np.concatenate(label_lst, axis=0)\n",
    "print(X_train_mnist.shape, Y_train_mnist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 21.55430602699562\n",
      "Step: 1 Error: 12.79036418714839\n",
      "Step: 2 Error: 10.449332868451698\n",
      "Step: 3 Error: 9.887053729385523\n",
      "Step: 4 Error: 9.800898147896659\n",
      "Step: 5 Error: 9.815214334244311\n",
      "Step: 6 Error: 9.834896190769467\n",
      "Step: 7 Error: 9.845415477558793\n",
      "Step: 8 Error: 9.849528857226625\n",
      "Step: 9 Error: 9.850784235545651\n",
      "Step: 10 Error: 9.851054568539878\n",
      "Step: 11 Error: 9.851066593403882\n",
      "Step: 12 Error: 9.851040316806355\n",
      "Step: 13 Error: 9.851022390846067\n",
      "Step: 14 Error: 9.8510144716984\n",
      "Step: 15 Error: 9.851011762971567\n",
      "Converged after 16 steps. Final Error: 9.851011059910311\n"
     ]
    }
   ],
   "source": [
    "W = tensor_to_tensor_regression_1(X_train_mnist, Y_train_mnist, 3, lambda_reg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lst = []\n",
    "label_lst = []\n",
    "for (image, labels) in train_loader:\n",
    "    np_image = image.detach().numpy().reshape((10000, 28, 28))\n",
    "    labels = labels.detach().numpy().reshape((10000, 1))\n",
    "    image_lst.append(np_image)\n",
    "    label_lst.append(labels)\n",
    "X_test_mnist = np.concatenate(image_lst, axis=0)\n",
    "Y_test_mnist = np.concatenate(label_lst, axis=0)\n",
    "Y_pred = tl.tenalg.contract(X_test_mnist, range(1, tl.ndim(X_test_mnist)), W, range(tl.ndim(X_test_mnist) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
