{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorly library\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TENSOR TO TENSOR REGRESSION v1    \n",
    "  Inputs:\n",
    "    X - Input Tensor, shape (N, I_1, ..., I_{M1})\n",
    "    Y - Output Tensor, shape (N, J_1, ..., J_{M2})\n",
    "    rank - The rank of the solution weights matrix\n",
    "    lambda_reg - how much l2 regularization to use\n",
    "    return_factors - whether to include the weight matrix factors along with the weight matrix itself\n",
    "    eps - the precision of our estimate\n",
    "    \n",
    "  Outputs:\n",
    "    W - weight matrix tensor, shape (I_1, ..., I_{M1}, J_1, ..., J_{M2})\n",
    "    factors - List of CP factors which forms the CP decomposition of W. Will only be returned if return_factors==True\n",
    "\"\"\"\n",
    "def tensor_to_tensor_regression_1(X, Y, rank, lambda_reg=0.0, return_factors=False, eps=1e-4):\n",
    "    # Check that the N is consistent between X and Y tensors\n",
    "    if X.shape[0] != Y.shape[0]:\n",
    "        print(\"Wrong leading dimensions for tensors X and Y\")\n",
    "    \n",
    "    # Number of examples (leading dimension in the tensor)\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Setup the sizes of the X and Y matrices\n",
    "    I = reduce(lambda x, y: x * y, X.shape[1:])\n",
    "    J = reduce(lambda x, y: x * y, Y.shape[1:])\n",
    "    \n",
    "    # Initialize the u_r and v_r vectors which we will directly optimize\n",
    "    u_rs = [np.random.random(I)-0.5 for r in range(rank)]\n",
    "    v_rs = [np.random.random(J)-0.5 for r in range(rank)]\n",
    "    \n",
    "    # Matricize X and Y\n",
    "    X_mat = tl.unfold(X, mode=0)\n",
    "    Y_mat = tl.unfold(Y, mode=0)\n",
    "    \n",
    "    # Precompute some repeatedly used matrices\n",
    "    XtXpL = np.matmul(np.transpose(X_mat), X_mat) + lambda_reg * np.identity(I)\n",
    "    XtXpL_inv = np.linalg.inv(XtXpL)\n",
    "    XtY = np.matmul(np.transpose(X_mat), Y_mat)\n",
    "    YtX = np.transpose(XtY)\n",
    "    \n",
    "    steps = 0\n",
    "    prev_error = -1\n",
    "    errors = [] # TODO: Remove for production (only used for testing)\n",
    "    # Keep optimizing until the error has converged\n",
    "    while steps < 100:\n",
    "        # For every rank of the weights matrix\n",
    "        for r in range(rank):\n",
    "            \n",
    "            # Update all the u_rs first\n",
    "            u_comp = np.zeros(I)\n",
    "            # Do some ugly linear algebra\n",
    "            for r1 in range(rank):\n",
    "                # Only want cases where r1 != r\n",
    "                if r1 == r:\n",
    "                    continue\n",
    "                # Computing the summation in equations (13) and (14)\n",
    "                u_comp += np.dot(v_rs[r1], v_rs[r]) * np.matmul(XtXpL, u_rs[r1])\n",
    "            # More ugly linear algebra, finishing off the calculation from 13 and 14\n",
    "            u_rs[r] = np.matmul(XtXpL_inv, np.matmul(XtY, v_rs[r])-(u_comp / 2)) / np.dot(v_rs[r], v_rs[r])\n",
    "            \n",
    "            # Now update all the v_rs\n",
    "            v_comp = np.zeros(J)\n",
    "            # Do some ugly linear algebra\n",
    "            for r1 in range(rank):\n",
    "                # Only want cases where r1 != r\n",
    "                if r1 == r:\n",
    "                    continue\n",
    "                v_comp += np.matmul(u_rs[r], np.matmul(XtXpL, u_rs[r1])) * v_rs[r1]\n",
    "            v_rs[r] = (np.matmul(YtX, u_rs[r]) - (v_comp / 2)) / np.matmul(u_rs[r], np.matmul(XtXpL, u_rs[r]))\n",
    "        \n",
    "        # Compute the new error, this time ignoring regularization\n",
    "        W_mat = np.zeros((I, J)) # TODO: implement\n",
    "        for r in range(rank):\n",
    "            # Add each W_r\n",
    "            W_mat += tl.tenalg.kronecker([u_rs[r], v_rs[r]]).reshape(I, J)\n",
    "        error = np.square(Y_mat - np.matmul(X_mat, W_mat)).mean()\n",
    "        errors.append(error)\n",
    "        # Determine if we have converged\n",
    "        if prev_error > 0 and abs(prev_error - error) < eps:\n",
    "            print(\"Converged after\", steps, \"steps. Final Error:\", error)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Step:\", steps, \"Error:\", error)\n",
    "        # Reset the previous error\n",
    "        prev_error = error\n",
    "        # Next step\n",
    "        steps += 1\n",
    "        \n",
    "    # Now we have converged, so return the W matrix\n",
    "    W = np.zeros((X.shape[1:]) + (Y.shape[1:])) # TODO: implement\n",
    "    # TODO: Add functionality to make the factors\n",
    "    return W_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 0.5997104511871522\n",
      "Step: 1 Error: 0.5849892012215819\n",
      "Step: 2 Error: 0.5887435723507122\n",
      "Step: 3 Error: 0.5935682517876575\n",
      "Step: 4 Error: 0.5961906877705239\n",
      "Step: 5 Error: 0.5970949301639201\n",
      "Step: 6 Error: 0.5972945657453477\n",
      "Converged after 7 steps. Final Error: 0.5972979544570927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.05572618,  0.01352623,  0.12380654,  0.04552046, -0.04707251,\n",
       "         0.33580541],\n",
       "       [ 0.05156074,  0.01251517,  0.11455218,  0.04211787, -0.04355391,\n",
       "         0.31070448],\n",
       "       [ 0.05944281,  0.01442834,  0.13206383,  0.04855643, -0.05021201,\n",
       "         0.35820181],\n",
       "       [ 0.08061205,  0.01956669,  0.17909534,  0.06584871, -0.06809388,\n",
       "         0.48576736],\n",
       "       [ 0.05628096,  0.01366087,  0.12503923,  0.04597367, -0.04754119,\n",
       "         0.33914868],\n",
       "       [ 0.05274597,  0.01280288,  0.1171854 ,  0.04308607, -0.0445551 ,\n",
       "         0.31784686],\n",
       "       [ 0.05318147,  0.01290854,  0.11815312,  0.04344181, -0.04492301,\n",
       "         0.32047114],\n",
       "       [ 0.0429334 ,  0.01042111,  0.09538475,  0.03507053, -0.03626627,\n",
       "         0.25871613],\n",
       "       [ 0.05901113,  0.01432358,  0.13110462,  0.04820377, -0.04984732,\n",
       "         0.35560031],\n",
       "       [ 0.07403394,  0.01796999,  0.16448089,  0.06047534, -0.06253731,\n",
       "         0.44612786],\n",
       "       [ 0.055219  ,  0.01340311,  0.12267984,  0.04510618, -0.04664412,\n",
       "         0.33274924],\n",
       "       [ 0.06271291,  0.01522209,  0.13932893,  0.05122762, -0.05297428,\n",
       "         0.37790731],\n",
       "       [ 0.05367874,  0.01302925,  0.11925787,  0.04384801, -0.04534306,\n",
       "         0.32346771],\n",
       "       [ 0.05830161,  0.01415133,  0.12952848,  0.04762423, -0.04924804,\n",
       "         0.35132497],\n",
       "       [ 0.05959967,  0.01446645,  0.13241215,  0.04868454, -0.05034446,\n",
       "         0.35914699],\n",
       "       [ 0.04949944,  0.01201483,  0.10997265,  0.04043409, -0.04181272,\n",
       "         0.29828315],\n",
       "       [ 0.0550121 ,  0.01335294,  0.1222199 ,  0.04493713, -0.04646927,\n",
       "         0.33150223],\n",
       "       [ 0.0500052 ,  0.01213759,  0.11109631,  0.04084722, -0.04223995,\n",
       "         0.30133083],\n",
       "       [ 0.06650503,  0.01614255,  0.14775383,  0.05432525, -0.05617752,\n",
       "         0.40075861],\n",
       "       [ 0.06885554,  0.01671308,  0.15297598,  0.05624531, -0.05816304,\n",
       "         0.41492289],\n",
       "       [ 0.05308571,  0.01288532,  0.11794021,  0.04336356, -0.04484207,\n",
       "         0.31989392],\n",
       "       [ 0.0588998 ,  0.01429655,  0.13085734,  0.04811285, -0.0497533 ,\n",
       "         0.35492957],\n",
       "       [ 0.05915424,  0.0143583 ,  0.13142276,  0.04832073, -0.04996827,\n",
       "         0.35646301],\n",
       "       [ 0.06125872,  0.01486914,  0.13609815,  0.05003978, -0.05174591,\n",
       "         0.36914453],\n",
       "       [ 0.04675018,  0.01134748,  0.10386475,  0.03818834, -0.03949043,\n",
       "         0.28171614],\n",
       "       [ 0.06273704,  0.01522796,  0.13938255,  0.05124736, -0.05299468,\n",
       "         0.3780529 ],\n",
       "       [ 0.05003747,  0.01214543,  0.11116799,  0.04087359, -0.04226721,\n",
       "         0.30152538],\n",
       "       [ 0.05914305,  0.01435559,  0.13139786,  0.04831158, -0.04995881,\n",
       "         0.35639557],\n",
       "       [ 0.05796309,  0.01406921,  0.12877615,  0.04734767, -0.04896201,\n",
       "         0.34928487],\n",
       "       [ 0.05653804,  0.01372329,  0.12561021,  0.04618362, -0.04775829,\n",
       "         0.3406976 ],\n",
       "       [ 0.04813311,  0.0116832 ,  0.10693698,  0.03931796, -0.04065853,\n",
       "         0.2900495 ],\n",
       "       [ 0.04457988,  0.0108207 ,  0.09904299,  0.03641551, -0.03765715,\n",
       "         0.26863795],\n",
       "       [ 0.05395065,  0.01309526,  0.11986191,  0.04407012, -0.04557273,\n",
       "         0.32510622],\n",
       "       [ 0.05691467,  0.01381465,  0.12644727,  0.04649132, -0.04807652,\n",
       "         0.34296739],\n",
       "       [ 0.04705518,  0.01142155,  0.10454216,  0.03843744, -0.039748  ,\n",
       "         0.28355387]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 20\n",
    "X = np.random.random((N, 5, 7))\n",
    "Y = np.zeros((N, 2, 3))\n",
    "# Setup Y tensor with some dummy data\n",
    "for n in range(N):\n",
    "    x = X[n]\n",
    "    Y[n] = np.array([[x[0, 0] + x[1, 1] , 2 * x[1, 0] - x[3, 2], (x[4, 5] + 1) ** 2],\n",
    "                    [-x[1, 6] + 3 * x[1, 5] ,  - x[0, 6] - x[3, 3], (x[2, 5] + 2) ** 2]])\n",
    "# Now fit it\n",
    "tensor_to_tensor_regression_1(X, Y, 3, lambda_reg=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7,  4,  5],\n",
       "       [10, 14,  8, 10],\n",
       "       [15, 21, 12, 15]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, 3]])\n",
    "arr2 = np.array([[5, 7, 4, 5]])\n",
    "tl.tenalg.kronecker([arr1, arr2]).reshape((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
