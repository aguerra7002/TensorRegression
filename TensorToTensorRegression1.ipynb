{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorly library\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TENSOR TO TENSOR REGRESSION v1    \n",
    "  Inputs:\n",
    "    X - Input Tensor, shape (N, I_1, ..., I_{M1})\n",
    "    Y - Output Tensor, shape (N, J_1, ..., J_{M2})\n",
    "    rank - The rank of the solution weights matrix\n",
    "    lambda_reg - how much l2 regularization to use\n",
    "    return_factors - whether to include the weight matrix factors along with the weight matrix itself\n",
    "    eps - the precision of our estimate\n",
    "    \n",
    "  Outputs:\n",
    "    W - weight matrix tensor, shape (I_1, ..., I_{M1}, J_1, ..., J_{M2})\n",
    "    factors - List of CP factors which forms the CP decomposition of W. Will only be returned if return_factors==True\n",
    "\"\"\"\n",
    "def tensor_to_tensor_regression_1(X, Y, rank, lambda_reg=1e-1, return_factors=False, eps=1e-6):\n",
    "    # Check that the N is consistent between X and Y tensors\n",
    "    if X.shape[0] != Y.shape[0]:\n",
    "        print(\"Wrong leading dimensions for tensors X and Y\")\n",
    "    \n",
    "    # Number of examples (leading dimension in the tensor)\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Setup the sizes of the X and Y matrices\n",
    "    I = reduce(lambda x, y: x * y, X.shape[1:])\n",
    "    J = reduce(lambda x, y: x * y, Y.shape[1:])\n",
    "    \n",
    "    # Initialize the u_r and v_r vectors which we will directly optimize\n",
    "    u_rs = [np.random.random(I)-0.5 for r in range(rank)]\n",
    "    v_rs = [np.random.random(J)-0.5 for r in range(rank)]\n",
    "    \n",
    "    # Matricize X and Y\n",
    "    X_mat = tl.unfold(X, mode=0)\n",
    "    Y_mat = tl.unfold(Y, mode=0)\n",
    "    \n",
    "    # Precompute some repeatedly used matrices\n",
    "    XtXpL = (tl.transpose(X_mat) @ X_mat) + lambda_reg * tl.eye(I)\n",
    "    XtXpL_inv = np.linalg.inv(XtXpL)\n",
    "    XtY = tl.transpose(X_mat) @ Y_mat\n",
    "    YtX = tl.transpose(XtY)\n",
    "    \n",
    "    steps = 0\n",
    "    prev_error = -1\n",
    "    #errors = [] # TODO: Remove for production (only used for testing)\n",
    "    # Keep optimizing until the error has converged\n",
    "    while True:\n",
    "        # For every rank of the weights matrix\n",
    "        for r in range(rank):\n",
    "            \n",
    "            # Update all the u_rs first\n",
    "            u_comp = tl.zeros(I)\n",
    "            # Do some ugly linear algebra\n",
    "            for r1 in range(rank):\n",
    "                # Only want cases where r1 != r\n",
    "                if r1 == r:\n",
    "                    continue\n",
    "                # Computing the summation in equations (13)\n",
    "                u_comp += (v_rs[r1] @ v_rs[r]) * (XtXpL @ u_rs[r1])\n",
    "            # More ugly linear algebra, finishing off the calculation from (13) \n",
    "            u_rs[r] = (XtXpL_inv @ ((XtY @ v_rs[r])-(u_comp / 2))) / (v_rs[r] @ v_rs[r])\n",
    "            \n",
    "            # Now update all the v_rs\n",
    "            v_comp = np.zeros(J)\n",
    "            # Do some ugly linear algebra\n",
    "            for r1 in range(rank):\n",
    "                # Only want cases where r1 != r\n",
    "                if r1 == r:\n",
    "                    continue\n",
    "                v_comp += (u_rs[r] @ XtXpL @ u_rs[r1]) * v_rs[r1]\n",
    "            v_rs[r] = ((YtX @ u_rs[r]) - (v_comp / 2)) / (u_rs[r] @ XtXpL @ u_rs[r])\n",
    "        \n",
    "        # Here comes the normalization step (ensures numerical stability)  \n",
    "        for r in range(rank):\n",
    "            u_scale = (tl.norm(v_rs[r], 2) / tl.norm(u_rs[r], 2)) ** 0.5\n",
    "            v_scale = 1 / u_scale\n",
    "            u_rs[r] *= u_scale\n",
    "            v_rs[r] *= v_scale\n",
    "        \n",
    "        # Compute the new error, this time ignoring regularization\n",
    "        W_mat = np.zeros((I, J))\n",
    "        for r in range(rank):\n",
    "            # Add each W_r\n",
    "            W_mat += tl.kron(u_rs[r], v_rs[r]).reshape(I, J)\n",
    "        # Use MSE to normalize the by the size of the tensor\n",
    "        error = np.square(Y_mat - X_mat @ W_mat).mean() + lambda_reg * np.square(W_mat).mean()\n",
    "        #errors.append(error)\n",
    "        # Determine if we have converged\n",
    "        if prev_error >= 0 and abs(prev_error - error) < eps:\n",
    "            print(\"Converged after\", steps, \"steps. Final Error:\", error)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Step:\", steps, \"Error:\", error)\n",
    "        # Reset the previous error\n",
    "        prev_error = error\n",
    "        # Next step\n",
    "        steps += 1\n",
    "        \n",
    "    \n",
    "    # TODO: Add functionality to make the factors\n",
    "    \n",
    "    return tl.reshape(W_mat, (X.shape[1:]) + (Y.shape[1:])) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 4.187710139472902\n",
      "Step: 1 Error: 5.427425206371436\n",
      "Step: 2 Error: 4.9988849742282735\n",
      "Step: 3 Error: 4.673435500330027\n",
      "Step: 4 Error: 4.428251184822083\n",
      "Step: 5 Error: 4.2798215775395425\n",
      "Step: 6 Error: 4.214043536002181\n",
      "Step: 7 Error: 4.199231549187298\n",
      "Step: 8 Error: 4.206932411397745\n",
      "Step: 9 Error: 4.219520426704756\n",
      "Step: 10 Error: 4.229418737321797\n",
      "Step: 11 Error: 4.235171413308442\n",
      "Step: 12 Error: 4.237823432126397\n",
      "Step: 13 Error: 4.2388057323003\n",
      "Step: 14 Error: 4.239129972410975\n",
      "Step: 15 Error: 4.23930403519958\n",
      "Step: 16 Error: 4.239499393582396\n",
      "Step: 17 Error: 4.239729324162558\n",
      "Step: 18 Error: 4.239961519485483\n",
      "Step: 19 Error: 4.240167783780741\n",
      "Step: 20 Error: 4.240336024857642\n",
      "Step: 21 Error: 4.24046665336701\n",
      "Step: 22 Error: 4.240565972787705\n",
      "Step: 23 Error: 4.240641414328005\n",
      "Step: 24 Error: 4.24069929347633\n",
      "Step: 25 Error: 4.240744273553565\n",
      "Step: 26 Error: 4.2407796075239945\n",
      "Step: 27 Error: 4.240807565056719\n",
      "Step: 28 Error: 4.240829787084753\n",
      "Step: 29 Error: 4.240847512525842\n",
      "Step: 30 Error: 4.240861704854572\n",
      "Step: 31 Error: 4.240873120963581\n",
      "Step: 32 Error: 4.240882353291759\n",
      "Step: 33 Error: 4.240889861342414\n",
      "Step: 34 Error: 4.240895998589082\n",
      "Step: 35 Error: 4.240901035937432\n",
      "Step: 36 Error: 4.240905181477483\n",
      "Step: 37 Error: 4.24090859633123\n",
      "Step: 38 Error: 4.240911406830175\n",
      "Step: 39 Error: 4.240913713570085\n",
      "Step: 40 Error: 4.240915597995608\n",
      "Step: 41 Error: 4.2409171271259085\n",
      "Step: 42 Error: 4.240918356925219\n",
      "Converged after 43 steps. Final Error: 4.240919334704501\n",
      "(5, 7, 2, 3)\n",
      "4.145343890818334\n"
     ]
    }
   ],
   "source": [
    "N = 11\n",
    "X = np.random.random((N, 5, 7))\n",
    "Y = np.zeros((N, 2, 3))\n",
    "# Setup Y tensor with some dummy data\n",
    "for n in range(N):\n",
    "    x = X[n]\n",
    "    Y[n] = np.array([[x[0, 0] + x[1, 1] , 2 * x[1, 0] - x[3, 2], (x[4, 5] + 1) ** 2],\n",
    "                    [-x[1, 6] + 3 * x[1, 5] ,  - x[0, 6] - x[3, 3], (x[2, 5] + 2) ** 2]])\n",
    "# Now fit it\n",
    "W = tensor_to_tensor_regression_1(X, Y, 5, lambda_reg=1)\n",
    "print(W.shape)\n",
    "# We can verify our answer is correct with the following\n",
    "Y_pred = tl.tenalg.contract(X, range(1, tl.ndim(X)), W, range(tl.ndim(X) - 1))\n",
    "print(np.square(Y_pred - Y).mean()) # Should print the same as the final error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 4.0214449899317515\n",
      "Step: 1 Error: 4.615278855711329\n",
      "Step: 2 Error: 4.330122752733615\n",
      "Step: 3 Error: 3.9053734534798177\n",
      "Step: 4 Error: 3.6026137719382403\n",
      "Step: 5 Error: 3.4503076963740353\n",
      "Step: 6 Error: 3.399219947618061\n",
      "Step: 7 Error: 3.397285823498813\n",
      "Step: 8 Error: 3.410641701689073\n",
      "Step: 9 Error: 3.423343543054102\n",
      "Step: 10 Error: 3.4308872772046177\n",
      "Step: 11 Error: 3.4339501762629157\n",
      "Step: 12 Error: 3.434492264382796\n",
      "Step: 13 Error: 3.434083972665766\n",
      "Step: 14 Error: 3.433562029351891\n",
      "Step: 15 Error: 3.433216856867045\n",
      "Step: 16 Error: 3.4330632900403915\n",
      "Step: 17 Error: 3.4330291269262503\n",
      "Step: 18 Error: 3.4330451177581387\n",
      "Step: 19 Error: 3.433070386632795\n",
      "Step: 20 Error: 3.4330887479150083\n",
      "Step: 21 Error: 3.433097858556881\n",
      "Step: 22 Error: 3.433100518950238\n",
      "Converged after 23 steps. Final Error: 3.4331000359015005\n",
      "0.09400153160095215\n"
     ]
    }
   ],
   "source": [
    "# For timing\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "W = tensor_to_tensor_regression_1(X, Y, 5, lambda_reg=10)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
