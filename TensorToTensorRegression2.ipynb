{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorly library\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TENSOR TO TENSOR REGRESSION v1    \n",
    "  Inputs:\n",
    "    X - Input Tensor, shape (N, I_1, ..., I_{M1})\n",
    "    Y - Output Tensor, shape (N, J_1, ..., J_{M2})\n",
    "    rank - The rank of the solution weights matrix\n",
    "    lambda_reg - how much l2 regularization to use\n",
    "    return_factors - whether to include the weight matrix factors along with the weight matrix itself\n",
    "    eps - the precision of our estimate\n",
    "    \n",
    "  Outputs:\n",
    "    W - weight matrix tensor, shape (I_1, ..., I_{M1}, J_1, ..., J_{M2})\n",
    "    factors - List of CP factors which forms the CP decomposition of W. Will only be returned if return_factors==True\n",
    "\"\"\"\n",
    "def tensor_to_tensor_regression_2(X, Y, rank, lambda_reg=0.0, return_factors=False, eps=1e-6):\n",
    "    # Check that the N is consistent between X and Y tensors\n",
    "    if X.shape[0] != Y.shape[0]:\n",
    "        print(\"Wrong leading dimensions for tensors X and Y\")\n",
    "    \n",
    "    # Number of examples (leading dimension in the tensor)\n",
    "    N = X.shape[0]\n",
    "    M1 = tl.ndim(X) - 1\n",
    "    M2 = tl.ndim(Y) - 1\n",
    "    \n",
    "    # Initialize the u_r and v_r vectors which we will directly optimize\n",
    "    Us = [np.random.random((X.shape[m1 + 1], rank))-0.5 for m1 in range(M1)]\n",
    "    Vs = [np.random.random((Y.shape[m2 + 1], rank))-0.5 for m2 in range(M2)]\n",
    "    \n",
    "    # Y vector \n",
    "    Y_vec = tl.tensor_to_vec(Y)\n",
    "    \n",
    "    steps = 0\n",
    "    prev_error = -1\n",
    "    #errors = [] # TODO: Remove for production (only used for testing)\n",
    "    # Keep optimizing until the error has converged\n",
    "    while steps < 100:\n",
    "        \n",
    "        # Optimizing all the Us\n",
    "        for m1 in range(M1):\n",
    "            C_r_mats = []\n",
    "            for r in range(rank):\n",
    "                # Columns we will kronecker together\n",
    "                cols_to_kron = []\n",
    "                for m1_p in range(M1):\n",
    "                    if m1_p != m1:\n",
    "                        # r-th column of U_m1\n",
    "                        cols_to_kron.append(Us[m1_p][:,r])\n",
    "                for m2_p in range(M2):\n",
    "                    cols_to_kron.append(Vs[m2_p][:,r])\n",
    "                contractor_shape = tuple(x for i, x in enumerate(X.shape[1:]) if i != m1) + Y.shape[1:]\n",
    "                contractor = tl.vec_to_tensor(tl.tenalg.kronecker(cols_to_kron), contractor_shape)\n",
    "                X_modes = [i for i in range(1, M1 + 1) if i != m1 + 1]\n",
    "                # Create the C_r tensor\n",
    "                C_r = tl.tenalg.contract(X, X_modes, contractor, range(M1 - 1)) \n",
    "                C_r_mats.append(tl.unfold(C_r, 1))\n",
    "            # This is the transpose of C\n",
    "            C_mat_t = tl.concatenate(C_r_mats, axis=0)\n",
    "            reg_mat = 0 # TODO: Remove\n",
    "            reg_mat = None\n",
    "            for m1_p in range(M1):\n",
    "                if m1_p != m1:\n",
    "                    to_dot = tl.transpose(Us[m1_p]) @ Us[m1_p] \n",
    "                    if reg_mat is None:\n",
    "                        reg_mat = to_dot\n",
    "                    else:\n",
    "                        reg_mat = reg_mat @ to_dot\n",
    "            for m2_p in range(M2):\n",
    "                to_dot = tl.transpose(Vs[m2_p]) @ Vs[m2_p]\n",
    "                if reg_mat is None:\n",
    "                    reg_mat = to_dot\n",
    "                else:\n",
    "                    reg_mat = reg_mat @ to_dot \n",
    "            reg_mat = lambda_reg * tl.tenalg.kronecker([reg_mat, tl.eye(X.shape[m1 + 1])])\n",
    "            U_vec = np.linalg.inv(C_mat_t @ tl.transpose(C_mat_t) + reg_mat) @ C_mat_t @ Y_vec\n",
    "            # Finally update the U_m1 matrix\n",
    "            Us[m1] = tl.vec_to_tensor(U_vec, Us[m1].shape)\n",
    "                \n",
    "        # Optimizing all the Vs    \n",
    "        for m2 in range(M2):\n",
    "            d_r_vecs = []\n",
    "            for r in range(rank):\n",
    "                # Columns we will kronecker together\n",
    "                cols_to_kron = []\n",
    "                for m1_p in range(M1):\n",
    "                    # r-th column of U_m1\n",
    "                    cols_to_kron.append(Us[m1_p][:,r])\n",
    "                for m2_p in range(M2):\n",
    "                    if m2 != m2_p:\n",
    "                        cols_to_kron.append(Vs[m2_p][:,r])\n",
    "                contractor_shape = X.shape[1:] + tuple(y for i, y in enumerate(Y.shape[1:]) if i != m2)\n",
    "                contractor = tl.tenalg.kronecker(cols_to_kron).reshape(contractor_shape)\n",
    "                # Create the C_r tensor\n",
    "                d_r = tl.tensor_to_vec(tl.tenalg.contract(X, range(1, M1 + 1), contractor, range(M1)))\n",
    "                d_r_vecs.append(d_r.reshape((d_r.shape[0], 1)))\n",
    "            D_mat = tl.concatenate(d_r_vecs, axis=1)\n",
    "            # Compute the regularization component\n",
    "            reg_mat = 0 # TODO: Remove\n",
    "            reg_mat = None\n",
    "            for m1_p in range(M1):\n",
    "                to_dot = tl.transpose(Us[m1_p]) @ Us[m1_p]\n",
    "                if reg_mat is None:\n",
    "                    reg_mat = to_dot\n",
    "                else:\n",
    "                    reg_mat = reg_mat @ to_dot\n",
    "            for m2_p in range(M2):\n",
    "                if m2_p != m2:\n",
    "                    to_dot = tl.transpose(Vs[m2_p]) @ Vs[m2_p] \n",
    "                    if reg_mat is None:\n",
    "                        reg_mat = to_dot\n",
    "                    else:\n",
    "                        reg_mat = reg_mat @ to_dot\n",
    "            reg_mat *= lambda_reg\n",
    "            # Get the correct Y_m2 matrix\n",
    "            Y_m2 = tl.unfold(Y, m2 + 1)\n",
    "            # Do the final update\n",
    "            Vs[m2] = Y_m2 @ D_mat @ np.linalg.inv(tl.transpose(D_mat) @ D_mat + reg_mat)\n",
    "        \n",
    "        # Normalization Step\n",
    "#         for r in range(rank):\n",
    "#             tot_norm = 1\n",
    "#             for m1 in range(M1):\n",
    "#                 nrm = tl.norm(Us[m1][:,r], 2)\n",
    "#                 tot_norm *= nrm\n",
    "#                 Us[m1][:,r] /= nrm\n",
    "#             for m2 in range(M2):\n",
    "#                 nrm = tl.norm(Vs[m2][:,r], 2)\n",
    "#                 tot_norm *= nrm\n",
    "#                 Vs[m2][:,r] /= nrm\n",
    "#             tot_norm = tot_norm ** (1 / (M1 + M2))\n",
    "#             for m1 in range(M1):\n",
    "#                 Us[m1][:,r] *= tot_norm\n",
    "#             for m2 in range(M2):\n",
    "#                 Vs[m2][:,r] *= tot_norm\n",
    "#             print(\"\\n\")\n",
    "#         print(\"-------\")\n",
    "        # Compute error here\n",
    "        # Construct W\n",
    "        weight_shape = X.shape[1:] + Y.shape[1:]\n",
    "        W = tl.zeros(weight_shape)\n",
    "        for r in range(rank):\n",
    "            to_kron = []\n",
    "            for m1 in range(M1):\n",
    "                to_kron.append(Us[m1][:,r])\n",
    "            for m2 in range(M2):\n",
    "                to_kron.append(Vs[m2][:,r])\n",
    "            W += tl.vec_to_tensor(tl.tenalg.kronecker(to_kron), weight_shape)\n",
    "        Y_pred = tl.tenalg.contract(X, range(1, M1 + 1), W, range(M1))\n",
    "        error = np.square(Y_pred - Y).mean() + lambda_reg * np.square(W).mean()\n",
    "        \n",
    "        # Determine if we have converged\n",
    "        if prev_error >= 0 and abs(prev_error - error) < eps:\n",
    "            print(\"Converged after\", steps, \"steps. Final Error:\", error)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Step:\", steps, \"Error:\", error)\n",
    "        # Reset the previous error\n",
    "        prev_error = error\n",
    "        # Next step\n",
    "        steps += 1\n",
    "        \n",
    "    return W\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 18.16275993069426\n",
      "Step: 1 Error: 8.09102742455311\n",
      "Step: 2 Error: 13.394514565302394\n",
      "Step: 3 Error: 68.07745768519946\n",
      "Step: 4 Error: 4.101118524355739\n",
      "Step: 5 Error: 171.950752783646\n",
      "Step: 6 Error: 13.88113686014119\n",
      "Step: 7 Error: 7946.069778940578\n",
      "Step: 8 Error: 46.92156033375949\n",
      "Step: 9 Error: 3.5928504992692605\n",
      "Step: 10 Error: 127.12702568455802\n",
      "Step: 11 Error: 139.43685628765854\n",
      "Step: 12 Error: 1289229.1316185007\n",
      "Step: 13 Error: 7.276515607389161\n",
      "Step: 14 Error: 11.704128450701049\n",
      "Step: 15 Error: 22.371921035986784\n",
      "Step: 16 Error: 338.1023565980306\n",
      "Step: 17 Error: 320.07950683184794\n",
      "Step: 18 Error: 163.4997733781796\n",
      "Step: 19 Error: 12.058214167353796\n",
      "Step: 20 Error: 8.528218405856506\n",
      "Step: 21 Error: 550.1893422456793\n",
      "Step: 22 Error: 13.600906615520042\n",
      "Step: 23 Error: 29.702306992717\n",
      "Step: 24 Error: 8.09158156871639\n",
      "Step: 25 Error: 42.954551589193684\n",
      "Step: 26 Error: 7.381048879196067\n",
      "Step: 27 Error: 7.539866427068356\n",
      "Step: 28 Error: 13.085139081550816\n",
      "Step: 29 Error: 236.98561856335454\n",
      "Step: 30 Error: 99.44982581142187\n",
      "Step: 31 Error: 18.74437343624485\n",
      "Step: 32 Error: 7.841305507577468\n",
      "Step: 33 Error: 6.510163826202004\n",
      "Step: 34 Error: 83.30524975615253\n",
      "Step: 35 Error: 1383.8000337395285\n",
      "Step: 36 Error: 19.134954198802383\n",
      "Step: 37 Error: 24.54063936715301\n",
      "Step: 38 Error: 518.2946306979172\n",
      "Step: 39 Error: 7.334047272192688\n",
      "Step: 40 Error: 10.85725061959863\n",
      "Step: 41 Error: 5.292472986904371\n",
      "Step: 42 Error: 9.055511863905018\n",
      "Step: 43 Error: 13.793789638330626\n",
      "Step: 44 Error: 8.142470073161677\n",
      "Step: 45 Error: 7.938533904553179\n",
      "Step: 46 Error: 16.275229863669196\n",
      "Step: 47 Error: 11117.632563713332\n",
      "Step: 48 Error: 23.23966696548962\n",
      "Step: 49 Error: 34.73356378170192\n",
      "Step: 50 Error: 6.114684339136038\n",
      "Step: 51 Error: 49.67937298472361\n",
      "Step: 52 Error: 301.6021055552222\n",
      "Step: 53 Error: 6.162521386723075\n",
      "Step: 54 Error: 28.16699726779128\n",
      "Step: 55 Error: 212.56182030349407\n",
      "Step: 56 Error: 56.26044164337389\n",
      "Step: 57 Error: 826.4976778068594\n",
      "Step: 58 Error: 32.09101951790195\n",
      "Step: 59 Error: 5.730978565932797\n",
      "Step: 60 Error: 8.578585657594775\n",
      "Step: 61 Error: 15.11692297368794\n",
      "Step: 62 Error: 37.24040767444662\n",
      "Step: 63 Error: 60.30699718390828\n",
      "Step: 64 Error: 10.62512374655505\n",
      "Step: 65 Error: 23.961551385417625\n",
      "Step: 66 Error: 10.743360869982421\n",
      "Step: 67 Error: 20.805197869796608\n",
      "Step: 68 Error: 16.342404181769766\n",
      "Step: 69 Error: 33157.57558963806\n",
      "Step: 70 Error: 12.706150358652794\n",
      "Step: 71 Error: 58.014562930283304\n",
      "Step: 72 Error: 10.521440231188151\n",
      "Step: 73 Error: 27.786061618649832\n",
      "Step: 74 Error: 9.61408030617568\n",
      "Step: 75 Error: 16.496961206106025\n",
      "Step: 76 Error: 11.662215891454233\n",
      "Step: 77 Error: 11.550039602833111\n",
      "Step: 78 Error: 8.250955400827763\n",
      "Step: 79 Error: 19.92546354446967\n",
      "Step: 80 Error: 11.277534440899714\n",
      "Step: 81 Error: 64.76277209366766\n",
      "Step: 82 Error: 120.67772889196885\n",
      "Step: 83 Error: 4.045626123514026\n",
      "Step: 84 Error: 5.547596015567042\n",
      "Step: 85 Error: 266.60826510891275\n",
      "Step: 86 Error: 217.3872977484945\n",
      "Step: 87 Error: 46.14937409466981\n",
      "Step: 88 Error: 16.767419566021495\n",
      "Step: 89 Error: 187.85123838409132\n",
      "Step: 90 Error: 11.856473100596686\n",
      "Step: 91 Error: 5.955482708809258\n",
      "Step: 92 Error: 2.791425593574105\n",
      "Step: 93 Error: 13.232778704710274\n",
      "Step: 94 Error: 11.589075908581432\n",
      "Step: 95 Error: 30.50570077705007\n",
      "Step: 96 Error: 230.35603997426136\n",
      "Step: 97 Error: 10.346880906233041\n",
      "Step: 98 Error: 11.60043010944743\n",
      "Step: 99 Error: 13.043085200810257\n",
      "(11, 5, 7)\n",
      "2.9400135293466256\n"
     ]
    }
   ],
   "source": [
    "N = 11\n",
    "X = np.random.random((N, 5, 7)) * 1\n",
    "Y = np.zeros((N, 2, 3))\n",
    "# Setup Y tensor with some dummy data\n",
    "for n in range(N):\n",
    "    x = X[n]\n",
    "    Y[n] = np.array([[x[0, 0] + x[1, 1] , 2 * x[1, 0] - x[3, 2], (x[4, 5] + 1) ** 2],\n",
    "                    [-x[1, 6] + 3 * x[1, 5] ,  - x[0, 6] - x[3, 3], (x[2, 5] + 2) ** 2]])\n",
    "# Now fit it\n",
    "W = tensor_to_tensor_regression_2(X, Y, 5, lambda_reg=10)\n",
    "# We can verify our answer is correct with the following\n",
    "print(X.shape)\n",
    "Y_pred = tl.tenalg.contract(X, range(1, tl.ndim(X)), W, range(tl.ndim(X) - 1))\n",
    "print(np.square(Y_pred - Y).mean()) # Should print the same as the final error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: 2.1202665140625734\n",
      "Step: 1 Error: 1.1475246083125783\n",
      "Step: 2 Error: 0.6778765144120024\n",
      "Step: 3 Error: 0.86160570805602\n",
      "Step: 4 Error: 2.967933629566618\n",
      "Step: 5 Error: 1.284519887069989\n",
      "Step: 6 Error: 2.829593085627063\n",
      "Step: 7 Error: 4.143177412073496\n",
      "Step: 8 Error: 1.9275961320727732\n",
      "Step: 9 Error: 2.6127807275000796\n",
      "Step: 10 Error: 1.2684087549879925\n",
      "Step: 11 Error: 0.7475411507168298\n",
      "Step: 12 Error: 1.2581483351679648\n",
      "Step: 13 Error: 1.138243391134839\n",
      "Step: 14 Error: 1.1051371668056194\n",
      "Step: 15 Error: 3.4863792514193053\n",
      "Step: 16 Error: 1.4131749332234727\n",
      "Step: 17 Error: 2.12466132070165\n",
      "Step: 18 Error: 0.802233048253556\n",
      "Step: 19 Error: 1.7191348388189736\n",
      "Step: 20 Error: 2.056671509889354\n",
      "Step: 21 Error: 1.041077093760336\n",
      "Step: 22 Error: 0.6813546797543508\n",
      "Step: 23 Error: 3.9765385522504957\n",
      "Step: 24 Error: 2.8978430024059962\n",
      "Step: 25 Error: 2.147042823074191\n",
      "Step: 26 Error: 0.678284034758313\n",
      "Step: 27 Error: 2.6581610830005586\n",
      "Step: 28 Error: 1.7814105261381614\n",
      "Step: 29 Error: 2.373750228334291\n",
      "Step: 30 Error: 1.2026624805268726\n",
      "Step: 31 Error: 1.8792462298663923\n",
      "Step: 32 Error: 3.845997119928935\n",
      "Step: 33 Error: 1.9594714006661562\n",
      "Step: 34 Error: 1.9431443067127303\n",
      "Step: 35 Error: 3.6486252177159804\n",
      "Step: 36 Error: 1.2521960643732761\n",
      "Step: 37 Error: 1.1546585040907533\n",
      "Step: 38 Error: 1.2355311130864721\n",
      "Step: 39 Error: 1.0019553310303542\n",
      "Step: 40 Error: 2.8817837036878275\n",
      "Step: 41 Error: 3.8103240508835223\n",
      "Step: 42 Error: 0.8558075596652323\n",
      "Step: 43 Error: 1.0484660115100812\n",
      "Step: 44 Error: 1.4831884974636123\n",
      "Step: 45 Error: 1.5338463022992277\n",
      "Step: 46 Error: 0.5675123970719992\n",
      "Step: 47 Error: 0.900666966746971\n",
      "Step: 48 Error: 1.6209817493412426\n",
      "Step: 49 Error: 3.5079362728612717\n",
      "Step: 50 Error: 0.9842287871775807\n",
      "Step: 51 Error: 1.6870012759352915\n",
      "Step: 52 Error: 1.1051245304537891\n",
      "Step: 53 Error: 1.1188765233888898\n",
      "Step: 54 Error: 3.9653911920649128\n",
      "Step: 55 Error: 2.9543075976914954\n",
      "Step: 56 Error: 1.2338050286190507\n",
      "Step: 57 Error: 4.903747668938294\n",
      "Step: 58 Error: 2.2808351607421966\n",
      "Step: 59 Error: 1.768602080500708\n",
      "Step: 60 Error: 2.58833935503907\n",
      "Step: 61 Error: 2.896150028250254\n",
      "Step: 62 Error: 1.2841230597572448\n",
      "Step: 63 Error: 2.362910796536659\n",
      "Step: 64 Error: 1.927006307570696\n",
      "Step: 65 Error: 4.088877117861372\n",
      "Step: 66 Error: 2.6671486090030623\n",
      "Step: 67 Error: 1.9693408817754938\n",
      "Step: 68 Error: 1.3011220819596263\n",
      "Step: 69 Error: 2.680609807850274\n",
      "Step: 70 Error: 0.9638109041391014\n",
      "Step: 71 Error: 2.5384715597535465\n",
      "Step: 72 Error: 0.908817345004916\n",
      "Step: 73 Error: 0.7907649031640646\n",
      "Step: 74 Error: 5.242478041776492\n",
      "Step: 75 Error: 3.345698665293215\n",
      "Step: 76 Error: 1.2281692546259433\n",
      "Step: 77 Error: 2.309390611326775\n",
      "Step: 78 Error: 1.555121327246713\n",
      "Step: 79 Error: 0.8866803239766814\n",
      "Step: 80 Error: 0.6236336134064868\n",
      "Step: 81 Error: 0.7517578797275407\n",
      "Step: 82 Error: 2.135128197226611\n",
      "Step: 83 Error: 0.7122119530656967\n",
      "Step: 84 Error: 1.3964098761228452\n",
      "Step: 85 Error: 1.4589109107494793\n",
      "Step: 86 Error: 2.192436839107841\n",
      "Step: 87 Error: 0.632392933615468\n",
      "Step: 88 Error: 1.9101410311765712\n",
      "Step: 89 Error: 5.151995314289827\n",
      "Step: 90 Error: 0.7612364771168133\n",
      "Step: 91 Error: 1.5445291577646485\n",
      "Step: 92 Error: 1.325882332635263\n",
      "Step: 93 Error: 1.2281476773690827\n",
      "Step: 94 Error: 1.434678284856519\n",
      "Step: 95 Error: 3.5111417763811326\n",
      "Step: 96 Error: 2.213504153782986\n",
      "Step: 97 Error: 3.363852421354548\n",
      "Step: 98 Error: 1.5777717798842126\n",
      "Step: 99 Error: 1.360480379953156\n",
      "0.6449975967407227\n"
     ]
    }
   ],
   "source": [
    "# For timing\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "W = tensor_to_tensor_regression_2(X, Y, 3, lambda_reg=10)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3, 3, 2, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(x for i, x in enumerate((9,5,3,3,2,1)) if i != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 4]\n",
      "[0, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr = [i for i in range(5) if i != 2]\n",
    "print(arr)\n",
    "arr.pop(1)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "cols_to_kron = [np.array([2, 3, 5]), np.array([7, 11, 13]), np.array([17, 19, 23])]\n",
    "kron = tl.tenalg.kronecker(cols_to_kron)\n",
    "arr = tl.vec_to_tensor(kron, (3, 3, 3))\n",
    "print(arr[0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
